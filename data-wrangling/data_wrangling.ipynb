{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "124ce8d4-12ce-4864-817b-884e6f024a43",
   "metadata": {},
   "source": [
    "# Data Wrangling\n",
    "The purpose of data wrangling is to transform data from its initial format to a format that are better for analysis. This process include cleaning, structuring and enriching raw data so that the data will be ready for analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b0dc8a0-5ac3-4c79-8f66-cb8cfeeca797",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f04e752-78ae-47b2-8b8c-175e3207a5a7",
   "metadata": {},
   "source": [
    "To demonstrate how data wrangling is done, I will use automobile dataset which is hosted on IBM Cloud object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b9aaa-c73f-44f6-b47b-d4e30742d68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_source = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/auto.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94373d3-2f81-44af-88b6-299628bc0c4e",
   "metadata": {},
   "source": [
    "The next step is creating python list of headers. The headers will be used to name each column in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0578b8-9759-417f-8d6b-34ac797f2901",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_headers = [\"symboling\",\"normalized-losses\",\"make\",\"fuel-type\",\"aspiration\", \"num-of-doors\",\"body-style\",\n",
    "         \"drive-wheels\",\"engine-location\",\"wheel-base\", \"length\",\"width\",\"height\",\"curb-weight\",\"engine-type\",\n",
    "         \"num-of-cylinders\", \"engine-size\",\"fuel-system\",\"bore\",\"stroke\",\"compression-ratio\",\"horsepower\",\n",
    "         \"peak-rpm\",\"city-mpg\",\"highway-mpg\",\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae614f0f-51c1-4759-8a3d-1b81114bea23",
   "metadata": {},
   "source": [
    "Then, I use `read_csv` method to load the data and set parameter names equal to *file_headers* variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b13543b-1987-4068-968c-419c784a4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(file_source, names=file_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaecde0-5be9-4fa7-aa03-4a8e7cde4ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head() # Display the first five rows of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b650439-f247-4f4e-817b-01a09dae68ec",
   "metadata": {},
   "source": [
    "## Identify Missing Value\n",
    "\n",
    "What do we do first after data has been loaded? We need to examine the dataset by looking maybe the first five or ten rows. One of the first thing to check is missing value. It is important because missing prevent us from doing good and right analysis. So, first thing to do is **identify missing value**. The preview of our dataset shows three cells with question marks, no value which indicates missing value and we need to deal with that. \n",
    "\n",
    "### 1. Convert \"?\" with `NaN`\n",
    "For convenient and performance reasons, as stated __[here](https://pandas.pydata.org/pandas-docs/version/2.0.1/user_guide/missing_data.html)__ we will convert \"?\" with `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4005eaf2-dede-4a22-a408-84fe90fac080",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.replace(\"?\", np.nan, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8715e1cf-b786-435a-ade7-152729e10beb",
   "metadata": {},
   "source": [
    "I used `inplace = True` because I want to change the original dataframe and we used Pandas `replace` method. As we can see in the preview, the \"?\" has been replaced by `NaN`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "956d64c1-ae5b-401b-b302-7ab7e5d8cefc",
   "metadata": {},
   "source": [
    "### 2. Evaluating Missing Data\n",
    "There are two useful functions for evaluating missing data; `isnull()` and `notnull`. The output will be boolean value indicating missing or non missing data. Those functions are opposite to each other. `isnull` will produce `True` for missing data and `False` for non missing data and vice versa for the other function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e34453c-f19b-4228-be81-f65703f68910",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data1 = df.isnull()\n",
    "missing_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3cba99-29c4-4a6a-aec8-b96f4b8ad3f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data2 = df.notnull()\n",
    "missing_data2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474cf976-86c9-4565-bb90-1c6c1654dfee",
   "metadata": {},
   "source": [
    "As we can see from both preview how those two functions produce different results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ad9d79-8ed6-41e5-b9f3-7ecfb896d94f",
   "metadata": {},
   "source": [
    "### 3. Count missing value in each column\n",
    "After evaluating missing data, we for sure want to count how many missing values exist in our dataset. We can achieve that by applying python `for` loop. I will use missing_data1 in this case. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "380a3346-8ca1-4af6-b619-79e7b17d6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in missing_data1.columns.values.tolist():\n",
    "    print(missing_data1[column].value_counts())\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd168064-4c97-4511-8e21-f47bc6437b05",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a6e5637c-0fa9-4c01-9b34-7205e3bd253e",
   "metadata": {},
   "source": [
    "Based on the summary above, each column has 205 rows. One important thing here is the missing data; 7 columns contain missing data. They are:\n",
    "1. *normalized-losses*: 41 missing data\n",
    "2. *num-of-doors*: 2 missing data\n",
    "3. *bore*: 4 missing data\n",
    "4. *stroke*: 4 missing data\n",
    "5. *horsepower*: 2 missing data\n",
    "6. *peak rpm*: 2 missing data\n",
    "7. *price*: 4 missing data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
